# -*- coding: utf-8 -*-
"""HR_tech-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HqIx49OVL4p5Yk4yDwubdJekNf8h591p
"""

#!pip install fuzzywuzzy python-Levenshtein

import pandas as pd
import numpy as np
import re
import spacy
from transformers import pipeline
from transformers import BartTokenizer, BartForConditionalGeneration
from fuzzywuzzy import fuzz
import warnings
warnings.filterwarnings('ignore')

#from google.colab import files

"""## **Data_loading**"""

df=pd.read_csv('Synthetic_data_HRTECH.csv')

df.head()

df['transcript'][0]

"""## **clean transcript**"""

def clean_transcript(text, candidate_name):
    text = str(text) if pd.notna(text) else ""

    if not text:
        return ""
    text = text.replace("Interviewer:", "").replace("Candidate:", "")
    text = re.sub(rf"{re.escape(candidate_name)}\s*[:\-]", "", text, flags=re.IGNORECASE)

    fillers = [
        "Sure, well,", "for sharing that", "Good to know", "That's helpful",
        "Could you elaborate on that", "How did your team respond to your decision",
        "Let's start with some questions", "To begin", "Great question","Tell me about"
        "for this opportunity", "Alright", "Got it","can you tell me about yourself","for joining","let's begin",
        " Do you have", "anything to ask us?","questions for us"
    ]
    for f in fillers:
        text = re.sub(rf"{re.escape(f)}[., ]*", "", text, flags=re.IGNORECASE)


    greetings = [
        "hello", "good morning", "good afternoon", "good evening",
        "thank you", "thanks", "nice to meet you", "hope you are doing well",
        "pleasure to be here", "thank you for having me","You're welcome"
    ]
    for g in greetings:
        text = re.sub(rf"\b{g}\b", "", text, flags=re.IGNORECASE)


    text = re.sub(r"\b(What|Why|How|Tell me|Can you)\b.*?\?", "", text)
    text = re.sub(r"[!?,.]{2,}", ". ", text)
    text = re.sub(r"\.{2,}", ". ", text)
    text = re.sub(r"\s+", " ", text).strip()

    return text

def final_clean_for_summary(text):

    text = re.sub(r"\b(\w+)-\1\b", r"\1", text)
    text = re.sub(r"(you know|uh|sure|well|great,|let's move|tell me about|let's begin|! for joining).*?,,!",
                  "", text, flags=re.IGNORECASE)
    text = re.sub(r"(tell me|describe your|which tools|any \?|you know|for this opportunity\.?)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"[\?\!]", "", text).strip()

    sentences = []
    for s in text.split("."):
        s = s.strip()
        if s and s not in sentences:
            sentences.append(s)
    text = ". ".join(sentences)

    text = re.sub(r"\s+", " ", text).strip()
    return text

df['clean_transcript'] = df.apply(lambda row: clean_transcript(row['transcript'], row['name']), axis=1)

df['clean_transcript'][0]

df['clean_transcript']=df['clean_transcript'].apply(final_clean_for_summary)

df['clean_transcript'][0]

"""## **Summarize**

"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM


model_name = "philschmid/bart-large-cnn-samsum"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def llm_recruiter_summary(text):
    prompt = """
You are an HR Recruiter. Summarize the candidate’s profile from the following interview transcript.
Focus only on:
- Key technical skills (e.g., Python, SQL, HR, Marketing, Project Management)
- Soft skills (e.g., communication, leadership, teamwork)
- Project experience or achievements
- Career goals or motivation

Do NOT include questions, fillers, stutters, 'you know', 'uh', or repeated lines.
Write in 4-5 clean recruiter-style sentences.

Transcript:
"""
    input_text = prompt + text[:3000]

    inputs = tokenizer.encode(input_text, return_tensors="pt", truncation=True, max_length=1024)

    summary_ids = model.generate(
        inputs,
        max_length=200,
        min_length=80,
        num_beams=6,
        no_repeat_ngram_size=3,
        length_penalty=1.3,
        early_stopping=True
    )

    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

text="""! for this opportunity.
— My strengths are employee engagement and communication.
 My last project involved communication and cross-functional coordination.
 Tell me about a recent technical/project you worked on.
  I want to deepen my expertise and lead a team of engineers/marketers.
  any ? I look forward to hearing from you. Describe your role in your last project.
   My so last project involved communication and cross-functional coordination.
   I well led a project where we used employee engagement to deliver a solution that improved metrics.
   I so take hands-on courses and apply them to projects.
   I take hands-on courses and apply them to projects.
    I you know worked on projects using employee engagement, communication, recruitment.
    Which tools and technologies do you use? That concludes our questions.
     Yes, I would like to know more about the team I’d be working with"""

res=llm_recruiter_summary(text)
print(res)

df['summary'] = df['clean_transcript'].apply(llm_recruiter_summary)

def clean_summary(summary):

    summary = re.sub(r"[^.]*\?", "", summary)

    summary = re.sub(r"(He would like to know.*?|He also wants to know.*?|He is looking for.*)", "", summary)

    summary = re.sub(r"\s+", " ", summary).strip()

    return summary

df['summary']=df['summary'].apply(clean_summary)

df['clean_transcript'][0]

df['summary'][0]

df.to_csv('summarized.csv')

#files.download('summarized.csv')

"""## **Sentiment--Key Word Matching**

"""

df=pd.read_csv('summarized.csv')

global_skills = [
    "python", "java", "c++", "sql", "excel", "power bi", "tableau",
    "machine learning", "deep learning", "nlp","django","pandas",
    "communication", "leadership", "teamwork",
    "git", "docker", "api", "cloud",
    "Jenkins for CI/CD",
    "algorithms", "data structures",
    "campaigns", "brand awareness", "digital marketing","pipeline",
    "seo", "branding", "digital marketing", "analytics",
    "recruitment", "employee engagement", "policy implementation",
    "agile", "scrum", "project management","detail-oriented",
    "communication", "leadership", "teamwork", "problem solving", "employee engagement",
    "collaboration", "stakeholder management","cross-functional coordination"

]

role_skill_map = {
    "Software Engineer": ["python", "java", "git", "api", "algorithms", "data structures"],
    "Data Analyst": ["sql", "excel", "power bi", "data visualization", "statistics", "python"],
    "Marketing Manager": ["campaigns", "brand awareness", "digital marketing", "seo", "content strategy"],
    "HR Executive": ["recruitment", "employee engagement", "onboarding", "policy implementation", "communication"],
    "Project Manager": ["agile", "scrum", "stakeholders", "risk management", "planning"],
    "AI ML Engineer": ["machine learning", "deep learning", "tensorflow", "pytorch", "nlp", "model deployment","ml","dl"]
}

def extract_skills(summary):
    detected = []
    for i in global_skills:
        if i in summary.lower():
          detected.append(i)
    return list(set(detected))

df['key_skills']=df['summary'].apply(extract_skills)

df['clean_transcript'][3]

df['summary'][3]

df['key_skills'][3]

df.head(5)

"""## **check --key skills**"""

def check_skills_in_summary(candidate_skills, required_skills_str, threshold=50):
    matched = 0
    required_skills = [skill.strip().lower() for skill in required_skills_str.split(',')]

    if not required_skills:
        return "Neutral"

    for req_skill in required_skills:
        for cand_skill in candidate_skills:
            if fuzz.partial_ratio(req_skill, cand_skill.lower()) > 70:
                matched += 1
                break

    total_required_skills = len(required_skills)
    match_percent = (matched / total_required_skills) * 100

    if match_percent > threshold:
        return "Positive"
    elif match_percent == threshold:
        return "Neutral"
    else:
        return "Negative"

df["JD_match"] = df.apply(
    lambda row: check_skills_in_summary(row["key_skills"], row["industry_skills"]),
    axis=1
)

df['JD_match'].value_counts()

"""## **Red flag detection**

"""

red_flag_phrases = [
    "i don't know", "not sure", "um", "uh", "you know",
    "blame", "issue with manager", "problem with team",
    "i didn't like", "i hate", "no idea", "confused"
]

def detect_red_flags(text):
    flags = []
    lower_text = text.lower()

    for phrase in red_flag_phrases:
        if phrase in lower_text:
            flags.append(phrase)

    if flags:
        return f"Red Flag  - {', '.join(flags)}"
    else:
        return "No Red Flag"

df["Red_Flag"] = df["summary"].apply(detect_red_flags)

df

df['Red_Flag'].value_counts()

"""## **Final_data**"""

df_final = df[(df['JD_match'] == 'Positive') & (df['Red_Flag'] == 'No Red Flag')]

df_final.shape

df_final=df_final.drop(columns=['Unnamed: 0'])

df_final=df_final.reset_index(drop=True)

df_final

df_final.columns

df_final=df_final.drop(columns=['Unnamed: 0.1'])



df_final.to_csv('FINAL_DATA.csv')

"""## **Save_models**"""

model.save_pretrained("/content/drive/MyDrive/saved_model/")
tokenizer.save_pretrained("/content/drive/MyDrive/saved_tokenizer/")